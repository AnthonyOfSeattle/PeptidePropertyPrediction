{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preliminaries-tokenizing-peptide-sequences.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjLCOdDS1CTEzngZE1K/rn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qjbq9FjuguTt"},"source":["# **Preliminary:** Encoding peptide sequences"]},{"cell_type":"markdown","metadata":{"id":"kCajgAHHhXSY"},"source":["## Intro"]},{"cell_type":"markdown","metadata":{"id":"3FL2eGcRhy1c"},"source":["In their digital form, DNA and Proteins are usually made up of sequences of letters -- nucleic acids (AATTGCA...) for the former and amino acids for the latter (MNPLLILTFV...) -- and while this form is relatively understandable for humans, it is difficult to work with for machine learning problems. It is important that we convert these sequences into something more friendly for learning algorithms, and that we think carefully about how will we do the conversion, since the algorithms available to us will depend highly on this step. To start out, I will list a few different options for a single peptide sequence, say PEPTIDEK."]},{"cell_type":"markdown","metadata":{"id":"bIEJrphpmRGT"},"source":["These are non-exhaustive but they should be useful in a broad range of circumstances. At first, I am going to talk largely abstractly about each of the different ways for encoding, and we will push off talking about their numpy representations until later."]},{"cell_type":"markdown","metadata":{"id":"7A1rHvXvoHZh"},"source":["#### **Amino Acid Counts**"]},{"cell_type":"markdown","metadata":{"id":"2djSSenioLrK"},"source":["One solution, is to list all possible amino acids and count their occurences in each of the peptides you are working with. For PEPTIDEK, this would look like:"]},{"cell_type":"markdown","metadata":{"id":"lBb8Y6Qmo8Vb"},"source":["```\n"," #A #C #D #E #F #G #H #I #K #L #M #N #P #Q #R #S #T #V #W #Y\n","  0  0  1  2  0  0  0  1  1  0  0  0  2  0  0  0  1  0  0  0\n","```"]},{"cell_type":"markdown","metadata":{"id":"QWHhIL-Hp5-P"},"source":["This a perfectly legitimate way to encode sequences, and has been popular for a long time. If your hypothesis is that what you are trying to predict, say retention time, is entirely determined by the composition of a peptide, then this is fine. Values for individual amino acids, such as hydrophobicity, can be combined with your counts to create a single number to represent each peptide."]},{"cell_type":"markdown","metadata":{"id":"ttyK9mwfrud6"},"source":["What this loses, however, is the postional information intrinsic to each amino acid. Do basic amino acids behave differently when postioned next to acidic amino acids? How does a proline behave at different positions in an amino acid sequence? You wouldn't be able to recover this information."]},{"cell_type":"markdown","metadata":{"id":"uEHw4flvsnyM"},"source":["#### **One Hot Encoding**"]},{"cell_type":"markdown","metadata":{"id":"ypwclz-DvXYu"},"source":["One of the most popular ways to retain position information is to use a one hot encoding of the sequence. This techinque envisions the sequence as a series of columns for each possible amino acid, with a series of rows representing a single postion in the sequence. We put a 1 where an amino acid appears and a 0, where it doesn't. Again, for the sequence PEPTIDEK, this would look like,"]},{"cell_type":"markdown","metadata":{"id":"su1T87rUw3dZ"},"source":["```\n","    A C D E F G H I K L M N P Q R S T V W Y\n","   ----------------------------------------\n"," 0| 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 1| 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 2| 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 3| 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 4| 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n"," 5| 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 6| 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 7| 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n","```"]},{"cell_type":"markdown","metadata":{"id":"Kqhfjnv6yfXt"},"source":["If you have not come accross this before, I encourage you to go through the above matrix and make sure that it does in fact spell PEPTIDEK. A representation like this contains a great deal of information. It encodes the amino acids and there position throughout the entire sequence. A good algorithm will make use of both, attempting to learn the effect of individual amino acid types on the property we want to predict as well as the sequence context those amino acids occur in."]},{"cell_type":"markdown","metadata":{"id":"QOzFzUrF0G2I"},"source":["It should be noted that you can arrive back at the Amino acid counts representation by walking down each individual column and counting up the number of 1's that you find."]},{"cell_type":"markdown","metadata":{"id":"WgoXlVau0qvX"},"source":["#### **Integer encoding**"]},{"cell_type":"markdown","metadata":{"id":"y2sM9uH307Qb"},"source":["An encoding closely related to the one above is the integer encoding. If we were to take a one hot encoding and walk accross the rows, recording each time which column a 1 appears in, we get a sequence of integers representing our sequence of amino acids. So for the first amino acid, we look at our sequence and see a P, which in the matrix would be column 13. The reason I start numbering the columns at 1 is due to padding, which will be explained bellow. For the sequence PEPTIDEK, this would look like,"]},{"cell_type":"markdown","metadata":{"id":"z2SxqFv02Kfk"},"source":["```\n","[13, 4, 13, 17, 8, 3, 4, 9]\n","```"]},{"cell_type":"markdown","metadata":{"id":"gK5vxcse2twe"},"source":["This representation provides much of the same information as one hot encoding, but makes unlocking certain functionality in deep learning packages a bit more streamlined."]},{"cell_type":"markdown","metadata":{"id":"e6ZG8NGy32Uw"},"source":["#### **Common Pitfalls**"]},{"cell_type":"markdown","metadata":{"id":"ZUmzqXOK5JVb"},"source":["**Modifications.** Chemical modifications are ubiquitous in genomics and proteomics. In just about every mass spec run, you will encounter oxidated methionine and phosphorylated residues that can have extremely different properties than their unmodified counterparts. These will be encoded in various ways depending on the programs in your pipeline. Here are a few examples for methionine oxidation,"]},{"cell_type":"markdown","metadata":{"id":"BKNmSpcu61AE"},"source":["- M[15.9949]\n","- M[16]\n","- M*\n","- M\\<ox>"]},{"cell_type":"markdown","metadata":{"id":"zm8oYS--7aXw"},"source":["In general, you will need to be careful jumping between these representatioins to tell any previously trained models that these are the same. In this notebook, we will focus on just one of these cases, and I will make note of how to deal with this kind of situation near the end."]},{"cell_type":"markdown","metadata":{"id":"FuWFbJv08WVi"},"source":["**Different length sequences.** This is of course something that you can't really avoid. Peptide sequences are almost never of uniform size, unless they are engineered to be so. Some deep learning frameworks are more forgiving about this than others, but at some point you run into a step where all the inputs need to be of uniform length. We usually do this with padding, i.e. the addition of dummy characters, usually 0, in order to extend a sequence to a final length. Here are the above examples for PEPTIDEK if we wanted it to have a final length of 10."]},{"cell_type":"markdown","metadata":{"id":"uhyoP-QdXjj8"},"source":["```\n","One Hot Encoded:\n","\n","    A C D E F G H I K L M N P Q R S T V W Y\n","   ----------------------------------------\n"," 0| 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 1| 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 2| 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 3| 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 4| 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n"," 5| 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 6| 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 7| 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 8| 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 9| 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","\n","Integer Encoded:\n","\n","[13, 4, 13, 17, 8, 3, 4, 9, 0, 0]\n","```"]},{"cell_type":"markdown","metadata":{"id":"MjD1MuaRX8u7"},"source":["How to do this uniformly accross sequences will be shown below."]},{"cell_type":"markdown","metadata":{"id":"lXV_pr_lYFqf"},"source":["## Tokenizing a list of sequences"]},{"cell_type":"markdown","metadata":{"id":"ZXleZa2wNL91"},"source":["Let's take the following list of peptides from trypsin as our input sequences. The major thing to notice here is that while a few amino acids occur in all the sequences, some amino acids only occur in one. The sequences are also all of different sizes so we will get some practice with padding."]},{"cell_type":"code","metadata":{"id":"LgHrTFaxZkob","executionInfo":{"status":"ok","timestamp":1615257045282,"user_tz":480,"elapsed":918,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}}},"source":["sequences = [\"IIRHPQYDR\",\n","             \"TLNNDIM[16]LIK\",\n","             \"VSTIS[80]LPTAPPATGTK\"]"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmMk9T2fPFgi"},"source":["#### **1. Conversion to tokens**"]},{"cell_type":"markdown","metadata":{"id":"_C-cHI73PNDr"},"source":["Since we want python to automatically register individual amino acids and their modifications, we are going to need to create a regular expression to recognize each token in turn. Here, the regular expression `\"[A-Z][^A-Z]*\"` will work just fine. It will first recognize a single amino acid `[A-Z]` and pick up any non-alphabetical letters that trail if present, like `[80]`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPhBU0c8YuWp","executionInfo":{"status":"ok","timestamp":1615257045284,"user_tz":480,"elapsed":901,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"44ab5f14-c10d-41fd-af81-1198101ca83b"},"source":["import re\n","\n","regex = \"[A-Z][^A-Z]*\"\n","tok_sequences = [re.findall(regex, seq) for seq in sequences]\n","\n","for seq in tok_sequences:\n","    print(seq)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["['I', 'I', 'R', 'H', 'P', 'Q', 'Y', 'D', 'R']\n","['T', 'L', 'N', 'N', 'D', 'I', 'M[16]', 'L', 'I', 'K']\n","['V', 'S', 'T', 'I', 'S[80]', 'L', 'P', 'T', 'A', 'P', 'P', 'A', 'T', 'G', 'T', 'K']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UiQEZH8_SCjs"},"source":["#### **2. Building our vocabulary**"]},{"cell_type":"markdown","metadata":{"id":"qnaqkQ4xSQJk"},"source":["Now that we have each sequence broken up into its individual amino acids, we need a way to determine all the amino acids that occur at least once. We will make use of two of pythons internal components to make our lives easier. The `set` obect will automatically deduplicate the tokens in our data, which is what we want. However, it requires them to be one after another, and not grouped into lists. To help, we can use `chain` from the `itertools` module, and specifically its `from_iterable` function, to automatically chain together the lists and feed them to the `set` constructor. I usually sort the tokens to offer some consistency between workflows."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJLASAN_aAXO","executionInfo":{"status":"ok","timestamp":1615257045286,"user_tz":480,"elapsed":894,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"16108c2e-45f3-4237-d128-dffd56cbabf5"},"source":["from itertools import chain\n","\n","aa_set = set( chain.from_iterable(tok_sequences) )\n","sorted_aa = sorted(aa_set)\n","vocab = {aa: ind for ind, aa in enumerate(sorted_aa, 1)}\n","\n","print(vocab)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["{'A': 1, 'D': 2, 'G': 3, 'H': 4, 'I': 5, 'K': 6, 'L': 7, 'M[16]': 8, 'N': 9, 'P': 10, 'Q': 11, 'R': 12, 'S': 13, 'S[80]': 14, 'T': 15, 'V': 16, 'Y': 17}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZnOz2PY2XzXU"},"source":["This should give you an automatically built vocab in the end. I would suggest manually writing an explicit vocab and saving it in a variable for projects where you want a lot of consistency, but for quick analyses, this works well. As I said above, you may need to tell your pipelines explicitly that two ways of writing oxidized methionine are actually the same. In order to do that, it may be easiest to just add a single token like so."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOKL463s_q73","executionInfo":{"status":"ok","timestamp":1615257045287,"user_tz":480,"elapsed":888,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"7ee871f3-47a9-43da-d981-0db274149154"},"source":["vocab[\"M<ox>\"] = 8\n","\n","print(vocab)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'A': 1, 'D': 2, 'G': 3, 'H': 4, 'I': 5, 'K': 6, 'L': 7, 'M[16]': 8, 'N': 9, 'P': 10, 'Q': 11, 'R': 12, 'S': 13, 'S[80]': 14, 'T': 15, 'V': 16, 'Y': 17, 'M<ox>': 8}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V-MQOECLXr7Y"},"source":["#### **3. Encoding**"]},{"cell_type":"markdown","metadata":{"id":"Fe5sttJjhymq"},"source":["We now have all we need to make our encodings. Regardless of which method I choose, I will usually build a blank matrix using `np.zeros` of the correct size and fill it in with encodings. This matrix is left as int32 for the integer encoding but as float32 for the one hot encoding. Deep learning frameworks often expect these types when they recieve the data."]},{"cell_type":"markdown","metadata":{"id":"aH-G-ef3kaBY"},"source":["At this point, there is probably several ways to do this in python. However, I think this works just fine and is quite easy to read."]},{"cell_type":"code","metadata":{"id":"3wNis5hooiO9","executionInfo":{"status":"ok","timestamp":1615257045288,"user_tz":480,"elapsed":885,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}}},"source":["import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zSK_nOSogm6"},"source":["**Integer Encoding**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrOnI9LPooeI","executionInfo":{"status":"ok","timestamp":1615257045289,"user_tz":480,"elapsed":878,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"f5e9da95-6d95-49ff-c98c-5264fef5f9f5"},"source":["vocab_size = max(vocab.values())\n","final_seq_length = max(map(len, tok_sequences))\n","\n","enc_sequences = np.zeros((len(tok_sequences), \n","                          final_seq_length),\n","                         dtype=np.int32)\n","for row_ind, seq in enumerate(tok_sequences):\n","    for col_ind, tok in enumerate(seq):\n","        enc_sequences[row_ind, col_ind] = vocab[tok]\n","\n","print(enc_sequences)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[[ 5  5 12  4 10 11 17  2 12  0  0  0  0  0  0  0]\n"," [15  7  9  9  2  5  8  7  5  6  0  0  0  0  0  0]\n"," [16 13 15  5 14  7 10 15  1 10 10  1 15  3 15  6]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FvRQcgAqomlq"},"source":["**One Hot Encoding**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkxzuReafJ8B","executionInfo":{"status":"ok","timestamp":1615257045570,"user_tz":480,"elapsed":1150,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"eaa5425a-adc4-4b6a-e623-73e1f1f177ec"},"source":["vocab_size = max(vocab.values())\n","final_seq_length = max(map(len, tok_sequences))\n","\n","enc_sequences = np.zeros((len(tok_sequences), \n","                          final_seq_length,\n","                          vocab_size),\n","                         dtype=np.float32)\n","for row_ind, seq in enumerate(tok_sequences):\n","    for col_ind, tok in enumerate(seq):\n","        enc_sequences[row_ind, col_ind, vocab[tok] - 1] = 1.\n","\n","print(enc_sequences)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n","  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o5D8WtX9rGa0"},"source":["#### **4. Wrapping everything together in a function**"]},{"cell_type":"markdown","metadata":{"id":"Cvt0dI5zAEfB"},"source":["Alright, we have now seen how to tokenize our sequences, build a vocabulary, and convert our sequences to encodings. We can put all of these together into a function to package up the pipeline and make it easily reusable. The only required argument is the sequences, but I provided custom arguments for each step which can be used to enforce consistency accross datasets. You can confirm that this gives the same results as above."]},{"cell_type":"code","metadata":{"id":"eCI3pZqYrOAW","executionInfo":{"status":"ok","timestamp":1615257045571,"user_tz":480,"elapsed":1144,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}}},"source":["import re\n","from itertools import chain\n","import numpy as np\n","\n","def one_hot_encode(sequences, regex=\"[A-Z][^A-Z]*\", vocab=None, seq_len=0):\n","    # 1. Conversion to tokens\n","    tok_sequences = [re.findall(regex, seq) for seq in sequences]\n","\n","    # 2. Build vocabulary if not supplied\n","    if vocab is None:\n","        aa_set = set( chain.from_iterable(tok_sequences) )\n","        sorted_aa = sorted(aa_set)\n","        vocab = {aa: ind for ind, aa in enumerate(sorted_aa, 1)}\n","\n","    # 3. Encode\n","    vocab_size = max(vocab.values())\n","    if seq_len == 0:\n","        seq_length = max(map(len, tok_sequences))\n","\n","    enc_sequences = np.zeros((len(tok_sequences), \n","                              seq_length,\n","                              vocab_size),\n","                             dtype=np.float32)\n","    for row_ind, seq in enumerate(tok_sequences):\n","        for col_ind, tok in enumerate(seq):\n","            enc_sequences[row_ind, col_ind, vocab[tok] - 1] = 1.\n","\n","    return enc_sequences"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpic9NxCr-pm","executionInfo":{"status":"ok","timestamp":1615257045572,"user_tz":480,"elapsed":1137,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"2f40aae2-3e05-496a-8b67-457aa2650f37"},"source":["print(\n","    one_hot_encode(sequences)\n","    )"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n","  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CPPL2IqgYbFU"},"source":["## **Bonus**: A scikit-learn compatable encoder"]},{"cell_type":"markdown","metadata":{"id":"9usjMA8Zzpyl"},"source":["In many situations it may be more useful to have pre-made solution which can interface with common machine learning packages such as scikit-learn. I make use of this in my own work to build longer pipelines for data processing. Bellow I will give a brief demo of a tool that I put together specifically for this purpose, which is available as a [**gist**](https://gist.github.com/AnthonyOfSeattle/43b932bcb9b5b4b00ccbe96c29769db9). In subsequent notebooks, I will show how this can be used alongside other models with a scikit-learn based interface to make pipelines."]},{"cell_type":"code","metadata":{"id":"qT4b9Ws_p5is","executionInfo":{"status":"ok","timestamp":1615257046418,"user_tz":480,"elapsed":1980,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}}},"source":["# The following is included to download the raw gist locally\n","import os\n","import requests\n","\n","if not os.path.exists(\"sequence_encoder.py\"): \n","    url = \"https://gist.githubusercontent.com/AnthonyOfSeattle/43b932bcb9b5b4b00ccbe96c29769db9/raw/a7a8bf8018a1e9a7b6900dfc61230718ea8843fb/sequence_encoder.py\"\n","    r = requests.get(url)\n","    with open(\"sequence_encoder.py\", \"wb\") as f:\n","        f.write(r.content)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7P0km1rr5KME"},"source":["#### **1. Initilization**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtEjdLTQ5JXM","executionInfo":{"status":"ok","timestamp":1615257047230,"user_tz":480,"elapsed":2785,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"1bc9ff53-043a-4506-9a67-107d11e8572c"},"source":["from sequence_encoder import SequenceEncoder\n","\n","help(SequenceEncoder.__init__)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Help on function __init__ in module sequence_encoder:\n","\n","__init__(self, pattern='\\\\w', vocab=None, seq_len=0, one_hot=False, oov_warn=True)\n","    Create an encoder class with optional fixed parameters.\n","    \n","    The most important parameter here is the regex `pattern`, which must be\n","    tailored to the given dataset. The optional `vocab` parameter can be\n","    used to pass a premade dictionary of token to integer correspondences.\n","    These will not be overwritten, but new tokens can still be learned.\n","    In the case that a predefined length is necessary, it can be determined\n","    by a possitive `seq_len` variable. Setting `seq_len` to a negative number,\n","    will allow the sequence lengths to by dyanmically determined. By default, \n","    the class will return data with an integer encoding, but a one hot encoding \n","    can be returned with `one_hot=True`. Finally, the class will spit out warnings \n","    when a token is not found in the vocabulary. In these cases, the position will \n","    be treated as a blank.\n","    \n","    Args:\n","        pattern (str): Regular expression for tokenizing sequences. Defaults to \\w.\n","        vocab (dict): Pre-built token to integer correspondences. Defaults to None.\n","        seq_len (int): Fixed sequence length for final encodings. Defaults to 0.\n","        one_hot (bool): Encoding toggle. False for integer, True for one hot. Defaults to False.\n","        oov_warn (bool): Warning toggle. Defaults to True.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2K_0PeHv23G5"},"source":["Once loaded, the `SequenceEncoder` class can be initialized with the regex pattern of your choice, which will be used to parse the passed sequences. In some cases, it may be advantageous to define a global vocabulary, which can be passed with the vocab parameter. An object which perform in a similar fashion to the anaysis above can be created like so."]},{"cell_type":"code","metadata":{"id":"Lrundhh3VQyD","executionInfo":{"status":"ok","timestamp":1615257047232,"user_tz":480,"elapsed":2783,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}}},"source":["encoder = SequenceEncoder(pattern=\"[A-Z][^A-Z]*\", seq_len=17, one_hot=True)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iBnsNLPL5agv"},"source":["#### **2. Training and Transformation**"]},{"cell_type":"markdown","metadata":{"id":"A68ukKS05dvc"},"source":["The real benefit of a tool like this is that it can be trained on a set of data, and maintain the mapping of amino acids to integers even on a new data set where some amino acids are missing. To train and store an amino acid to integer mapping, simply call the `fit` method."]},{"cell_type":"code","metadata":{"id":"pt1UOp95WJNh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615257047234,"user_tz":480,"elapsed":2779,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"5c66e809-4b55-407a-a95a-a06495dca97b"},"source":["sequences = [\"IIRHPQYDR\",\n","             \"TLNNDIM[16]LIK\",\n","             \"VSTIS[80]LPTAPPATGTK\"]\n","\n","encoder.fit(sequences)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sequence_encoder.SequenceEncoder at 0x7fecb536ff50>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"rZpijjLd6Zla"},"source":["We can then transform the data using the `transform` function. A single sequence can be passed or a list of sequences."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bZ32E5D0F7N","executionInfo":{"status":"ok","timestamp":1615257047235,"user_tz":480,"elapsed":2773,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}},"outputId":"5d17f35d-9663-443e-e31a-a8ac8afeab0d"},"source":["print(\n","    encoder.transform(\"TLNNDIM[16]LIK\")\n",")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gDrPHXE1LKtf","executionInfo":{"status":"ok","timestamp":1615257047236,"user_tz":480,"elapsed":2771,"user":{"displayName":"Anthony Valente","photoUrl":"","userId":"15546957659826287844"}}},"source":[""],"execution_count":14,"outputs":[]}]}